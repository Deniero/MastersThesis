\chapter{Foundations}
\label{chap:foundations}
This chapter will provide an overview of both genetic algorithms as well as behavior trees. Both tools are required by the proposed approach. The genetic algorithm will search for critical situations by controlling all NPCs, while the behavior tree will be specifically applied to the EGO vehicle.

\section{Genetic Algorithm}
\label{sect:foundations:genetic_algorithm}
Pioneered by Holland~\cite{holland_adaptation_1992}, genetic algorithms emulate the process of natural selection and the darwinian principle known as 'survival of the fittest'. Genetic algorithms are a subclass of evolutionary algorithms (EAs) and explore the solution space using a population of individuals \cite{mills_determining_2015}. Each individual contains one chromosome, which serves as a candidate solution. Using genetic operations, the individuals mate among themselves and mutate independently. 

The selection of an individual is determined by a fitness function, which defines the search problem. Each individual has a fitness value corresponding to the performance of its chromosome~\cite{majumdar_genetic_2015}. Individuals that perform poorly on the given problem die out, while individuals deemed 'strong' propagate. Genetic algorithms optimize iteratively, with each iteration referred to as a generation. Chromosomes consist of individual genes and form a solution to the search problem. Through successive generations using genetic operations, gene values and position are optimized, resulting in progressively improved solutions~\cite{srinivas_genetic_1994}. Generational genetic algorithms, where the entire population is replaced each generation, will be utilized in this master's thesis. In contrast, steady state genetic algorithms only replace a small fraction of the population at a time~\cite{srinivas_genetic_1994}.

This search method, on the basis of biological principles, enables a global and dispersed search through its population, which avoids various shortcomings of local search techniques~\cite{grefenstette_optimization_1986}. Particularly on challenging search spaces with multiple local optima, a GA is less prone to getting stuck on a suboptimal solution~\cite{majumdar_genetic_2015, katoch_review_2021, xia_genetic_2019}. Genetic algorithms offer advantages for complex optimization and non-deterministic polynomial problems~\cite{hussain_trade-off_2020}.

\begin{quote}
	\begin{em}
		\enquote{GAs can find good solutions within a large, ill-defined search space, and can be readily adapted to a wide variety of search problems}~\cite{mills_determining_2015}
	\end{em}
\end{quote}

Grefenstette~\cite{grefenstette_optimization_1986} further emphasis its ability to outperform gradient techniques on challenging problems with high-dimensional, noisy or discontinuous fitness functions by efficiently exploiting a \enquote{relatively simple selection mechanism.} The primary advantage of a GA in tackling these problems stems from its capability to explore the search space using its entire population~\cite{hussain_trade-off_2020}. A basic GA, as proposed by Holland~\cite{holland_adaptation_1992} can be defined as follows:

\begin{lstlisting}[language=C, tabsize=4]
simple_genetic_algorithm() 
{
	initialize_population();
	evaluate_population();
	for(int i = 0; i < num_of_generations; i++) 
	{
		select_individuals_for_next_population();
		perform_crossover();
		perform_mutation();
		evaluate_population();
	}
}
\end{lstlisting}

The population is initialized randomly, and its individuals are subsequently evaluated using the fitness function. The following steps are iteratively repeated until some stopping criterium is triggered. Initially, individuals are chosen using a selection operation, which takes their fitness value under consideration. Subsequently, a crossover rate determines which individuals mate using a crossover function. This operation serves the purpose of exchanging information between the chromosomes. In order to add variation and diversity, the resulting crossover offspring undergoes small changes using a mutation function. A mutation rate decides which individuals undergo  this operation. The newly generated population is then evaluated for the next iteration. Different stopping methods like time limit, fitness limit, minimum convergence rate or maximum number of generations are available~\cite{majumdar_genetic_2015}.

As discussed by Hussain and Muhammad~\cite{hussain_trade-off_2020}, genetic algorithms face an exploration vs exploitation dilemma. If the algorithm converges too quickly to a solution, most of the search space might not have been explored yet, thus increasing the probability of getting stuck in a local optimum.
In contrast, a low convergence rate might be time consuming and result in inefficient utilization of computational resources.

\begin{quote}
	\begin{em}
		\enquote{Finding a balance between exploration and exploitation has been a difficult-to-achieve goal from the beginning.}~\cite{kacprzyk_parameter_2007}
	\end{em}
\end{quote}

Attaining this balance requires a suitable choices on both genetic functions and their applied probabilities. Due to no real consensus on the best control parameter settings, their optimal selection proves to be difficult~\cite{kacprzyk_parameter_2007}.

\subsection{Chromosomes and Genes}
\label{sect:foundations:chromosomes_and_genes}
Both chromosomes as well as genes require suitable encodings in order to fit the search task. Each chromosome, composed of a list of genes, must represent a complete solution of the specific problem. Finding appropriate encodings proved to be, besides the hyperparameter tuning, the main challenge in setting up a genetic algorithm pipeline.

While the chromosome encoding is highly problem specific and heavily depends on the choice of gene encoding, there are various gene encodings suggested by existing literature. A simple and commonly used representation for genes is binary encoding, where a gene takes on the form of either zero or one. Further common encodings include octal and hexadecimal representations~\cite{srinivas_genetic_1994,katoch_review_2021}. Srinivas and Patnaik~\cite{srinivas_genetic_1994} also suggest integer representations in case a optimization problem has real-valued continuous variables, where the objects are linearly mapped to integers defined in a specific range. Various other encodings are available, often very problem specific. For example tree encodings allows for genes to represent programming functions, leading to a subcategory of genetic algorithms called 'genetic programming'~\cite{katoch_review_2021}. In cases where existing gene encodings do not fit the given problem, custom encodings can be employed.

\subsection{Population Size}
The population size, which defines the number of individuals per generation, directly impacts the performance of a genetic algorithm. Increasing the population size will enhance the degree of parallelism in the genetic algorithm, as each individual represents one distinct search point~\cite{mills_determining_2015}.

Research seams to be in agreement, that a small population leads to less diverse individuals and might provide an insufficient sample size, which can result in premature convergence to a local optimum. A large population size will allow the GA to perform a more informed search. However computation time will suffer due to the larger number of individuals per generation and might lead to slower convergence to an optimum \cite{grefenstette_optimization_1986, katoch_review_2021, kacprzyk_parameter_2007}).

\subsection{Selection}
The selection operator chooses two parents for crossover and mutation operations until the list of offsprings has reached the desired population size. Individuals are chosen based on their fitness value, ensuring their increased representation from generation to generation. Weak solutions will be discarded over time~\cite{srinivas_genetic_1994}. The selection algorithm must satisfy two requirements. On the one hand, high selection pressure will lead to decreased diversity in the population resulting in premature convergence~\cite{katoch_review_2021}. The algorithm will subsequently behave more like a local search method, a hill-climber or a greedy algorithm ~\cite{kacprzyk_parameter_2007}. The initial low average fitness value of the population will, in combination with a few well performing individuals lead to them overtaking the population, drastically reducing diversity. On the other hand, low selection pressure will struggle to converge to an optimum. Different selection methods like stochastic uniform remainder, random selection, rank selection, roulette wheel selection and tournament selection exist~\cite{majumdar_genetic_2015}. According to Hussain and Muhammad~\cite{hussain_trade-off_2020}, who provide a extensive comparison of different selection techniques, the choice of selection methods significantly affects the performance of the genetic algorithm.

Roulette wheel selection is a popular mechanism, where each individual corresponds to an area on a roulette wheel, based on its fitness value~\cite{holland_adaptation_1992}. Grefenstette~\cite{grefenstette_optimization_1986} points out the scaling problem as its major drawback. As the algorithm progresses, its fitness variance to mean ratio becomes increasingly small, leading to low selection pressure. This problem can be mitigated by using ranks instead of the fitness value~\cite{katoch_review_2021}. Individuals will be sorted based on their performance and their relative ranks are then inserted into the roulette wheel instead. 

Tournament selection is a popular alternative to roulette wheel selection. A parameter \textit{t} defines the size of a tournament. Until the desired number of offsprings is achieved, \textit{t} individuals will be chosen at random from the population. Only from this smaller list, the best individual is selected. A popular tournament size is 2, larger sizes might enhance competition among individuals, however they can also has an impact on the diversity of the population~\cite{hussain_trade-off_2020}. In a comparison of different selection methods by Jinghui Zhong et al.~\cite{jinghui_zhong_comparison_2005}, tournament selection was deemed to be the most performant, converging more quickly than for example roulette wheel selection.

Elite selection is an additional method that can enhance a selection operation and was proposed by De Jong~\cite{de_jong_analysis_1975}. The best \textit{n} individuals are automatically chosen for the next generation. Elite selection can help reduce variance, as the highest performing individuals can not be removed by randomness.

\subsection{Crossover}
The crossover operation serves as the mating process between two individuals chosen from the population by the selection operation. The resulting offspring is a combination of both parent genes. Grefenstette~\cite{grefenstette_optimization_1986} highlights, that first, \enquote{it provides new points for further testing within the hyperplanes already represented in the population} and second, that it \enquote{introduces representatives of new hyperplanes into the population}. 

Different types of crossovers can be implemented, with the simplest approach being the single-point crossover. In this method, a point is chosen at random along the length of the chromosome. The two parents swap their genetic information at this position, generating two new offsprings~\cite{katoch_review_2021}. Extension are the two- or \textit{k}-point crossover operations, where chromosomes are divided by \textit{k} segments, which will get exchanged. A second crossover operation is named uniform crossover, where gene swaps between parents are randomly decided by a given probability, independent to the exchange of other genes~\cite{katoch_review_2021}. Lim et al.~\cite{lim_crossover_2017} demonstrate various other crossover operations.

Srinivas and Patnaik~\cite{srinivas_genetic_1994} proposed the notion of positional and distributional bias. If a crossover operation has a positional bias, the probability of a bit to be swapped depends mainly on its position. Examples of this are the mentioned single and \textit{k}-point crossover operators. The uniform crossover can be found at the other end of the spectrum, as it has a maximal distributional bias, completely disregarding any positional information. While ignoring gene positions results in higher disruptiveness, which has potential drawbacks, it becomes more exploratory in homogeneous populations where \textit{k}-point crossovers might struggle. Srinivas and Patnaik~\cite{srinivas_genetic_1994} suggest that uniform crossover is more useful in small populations. Larger populations inherently are more diverse, making k-point crossover more suitable.

Not only the crossover type has to be chosen, a crossover rate also requires declaration. This value defines how likely a single crossover operation is to be applied on the selected individuals. Choosing a suitable crossover probability is, again, influenced by the exploration-exploitation balance. Higher crossover rates will introduce new structures quickly into the population; however, good sequences of genes might get disrupted. A low crossover rate will result in a low exploration, which leads to stagnation~\cite{grefenstette_optimization_1986}.

\subsection{Mutation}
The mutation operation is applied after crossover to maintain the diversity of the gene pool. Through small, random changes, the variability of the population increases. Each individual can be exposed to mutation, irrespective of their fitness value. A mutation rate chooses the individuals to be mutated. An additional individual mutation rate selects which specific genes of the chosen chromosome are mutated~\cite{srinivas_genetic_1994}. Depending on the gene encoding, the mutation operation might vary. In case of binary gene encoding, mutation will only flip certain bits. For custom encodings, the mutation operation can be tailored accordingly.

\begin{quote}
	\begin{em}
		\enquote{If the mutation is not considered during evolution, then there will be no new information available for evolution.}~\cite{katoch_review_2021}
	\end{em}
\end{quote}

The settings for mutation rates again need to be chosen carefully. If they are too high, the genetic algorithm might transform into random testing. In case they are set too low, the population will not be able to maintain diversity as no new genetic material is reintroduced~\cite{klampfl_using_nodate, grefenstette_optimization_1986}).

\subsection{Adaptive Control Parameters}
Various pieces of literature~\cite{hussain_trade-off_2020, marsili_libelli_adaptive_2000, karafotias_parameter_2015} suggest adaptively controlling selection methods, crossover rates and mutation rates over the duration of a genetic algorithm. The main goal is to mitigate the previously mentioned exploration-exploitation problem. In the beginning, exploration is desired, thus low selection pressure as well as high crossover and mutation rates are required. However towards the end of the genetic algorithms duration, convergence to an optimum is preferred, meaning more 'elite' selection methods as well as less variation due to crossover and mutation~\cite{srinivas_genetic_1994}.

Marsili Libelli and Alba~\cite{marsili_libelli_adaptive_2000} proposed a method where different mutation rates are used depending on the fitness of the individual. They claim that a higher mutation probability for a low fitness population results in a more efficient search. Hussain and Muhammad~\cite{hussain_trade-off_2020} argue for a selection operation, where initially low selection pressure is applied while increasing it towards the end, stating that this approach will help mitigate both mentioned competing criteria, namely premature convergence as well as slow convergence.

Contrary, De Jong~\cite{kacprzyk_parameter_2007} is more critical on adaptive control parameters. Although they might improve the performance of a genetic algorithm for specific problems, genetic algorithms are already quite robust in practice. Adding more tunable parameters will not make the task of the researcher easier.

\begin{quote}
	\begin{em}
		\enquote{The purist might argue that inventing feedback control procedures for EAs is a good example of over-engineering an already sophisticated adaptive system.} \cite{kacprzyk_parameter_2007}
	\end{em}
\end{quote}

He adds, that \enquote{perhaps the most interesting thing to note today, after more than 30 years of experimenting with dynamic parameter setting strategies, is that, with one exception, none of them are used routinely in every day practice. The one exception are the strategies used by the ES community for mutation step size adaptation.} In order to keep the number of tunable parameters low, the approach implemented by this master's thesis will not utilize adaptive control parameters.

\section{Behaviour Tree}
Behavior trees were invented and developed by the computer game industry as a control structure of non-player characters~\cite{collendanchise_behavior_2019}. Since then, their scope of application has expanded into various fields, including robotics, smart homes, power grids, autonomous vehicles~\cite{iovino_survey_2022}. Sprague et al.~\cite{sprague_improving_2018} demonstrated their effectiveness as a robust control architecture for autonomous underwater vehicles. A behavior tree is a directed tree, with root, child, parent and leaf nodes. Control flow nodes are non-leaf nodes, while leaf nodes are known as execution nodes. The execution of a BT occurs through ticks, propagating down down the tree, starting from the root node at a specified frequency. When receiving a tick, all nodes execute and can return either "Running", "Success" or "Failure"~\cite{collendanchise_behavior_2019}.

Their high modularity and reactiveness are often stated as their main advantages. The modularity stems from the fact, that different parts in the BT can be changed and modified without influencing the rest of the tree. This aligns with the reactivity demonstrated by the Behavior Tree. Per tick, safety tests can be performed before entering the execution logic of the tree, allowing the system to react immediately to a non-safe situation. Adding complex details to this execution sub-tree will not jeopardise the safety tests~\cite{sprague_improving_2018}.

\subsection{Control Flow and Execution Nodes}
The control flow nodes decide which actions and condition nodes to execute next. Three categories of control flow nodes - Sequence, Fallback and Parallel - exist. The two execution nodes are Actions and Conditions, both are responsible for carrying out the actual behavior of the behavior tree~\cite{collendanchise_behavior_2019}.

\begin{itemize}
	\item Control flow nodes
	\begin{itemize}
		\item \textbf{Sequence nodes:} These nodes execute their children nodes sequentially, routing the ticks to each child as long as they return "Success".  If every child returns "Success," the sequence node itself returns "Success." If any child returns "Failure" or "Running", the sequence node immediately returns the corresponding value without routing the tick to the next child.
		
		\item \textbf{Fallback nodes:} Fallback nodes execute their children one after another until one child returns "Success" or "Running", at which point will the fallback node returns "Success" or "Running" accordingly. As long as the childs status is "Failure", they will continue routing the ticks to the next child. If all children return "Failure", the fallback node will also returns "Failure".
		
		\item \textbf{Parallel nodes:} These nodes execute all children simultaneously. Given a parameter \textit{m}, they decide on its return status. If more than \textit{m} children succeeded, it will return "Success".  If enough children fail to make "Success" impossible, they return "Failure"; otherwise, they return "Running."
	\end{itemize}
	\item Execution nodes
	\begin{itemize}
		\item \textbf{Action nodes:} These nodes execute a command upon receiving a tickand can return "Success," "Failure," or "Running." Typically, action nodes execute the behavior of an agent, such as "open\_door()".
		
		\item \textbf{Condition nodes:} These nodes also execute a command after receiving a tick. Contrary to the  Action Nodes, they can only return "Success" and "Failure".  Condition nodes are designed to check conditions, such as "is\_door\_closed()". They cannot execute over multiple ticks and thus can never return "Running".
	\end{itemize}
\end{itemize}