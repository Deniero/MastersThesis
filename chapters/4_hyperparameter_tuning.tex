\chapter{Hyperparameter Tuning}
\label{chap:hyperparameter_tuning}
The performance of a genetic algorithm is significantly influenced by its control parameters. Performant settings on one particular fitness landscape might not be appropriate a different one. (\cite{kacprzyk_parameter_2007}).

\todo{explain No Free Lunch Theorem better}
According to the "No Free Lunch Theorem", no single algorithm will outperform all other algorithms on a single class of problem (\cite{kacprzyk_parameter_2007}). \cite{kacprzyk_parameter_2007} further states, that "the No Free Lunch results place an obligation on the EA practitioner to understand something about the particular properties of the problems that (s)he is trying to solve that relate to particular choices of EA parameter settings."
A human-in-the-loop approach is needed to fine-tune parameter settings to a particular problem.

This Chapter will focus on tuning the genetic algorithm to perform well on the given cost function. First, a choice on the optimal population size is made. Afterwards a Taguchi method is used for tuning the remaining hyperparameter.

\section{Simulation Setup}
\label{sect:hyperparameter_tuning:simulation_setup}
Two workstations were available for running all of the following simulations. The first workstation had an Intel Core i7-9700K and a GeForce RTX 2070 SUPER with 32 GB of RAM. The second workstation had an Intel Core i7-6850K as well as two Nvidia GeForce GTX 1080 also with 32 GB of RAM. On both systems, Kubuntu 20.04 LTS was the operating system.

As has been defined in Chapter \ref{chap:implementation}, each genetic algorithm will run for 30 generations. Additionally 1 simulation will have a duration of 35 seconds. On a single workstation, it takes approximately 3 hours and 50 minutes to complete one genetic algorithm with a population size of 96. This time indication is however influenced by the number of actors. 

Town 10 from the driving simulator Carla\footnote{\href{https://carla.readthedocs.io/en/latest/map_town10/}{https://carla.readthedocs.io/en/latest/map\_town10/}} will be used as the map for all experiments. It has an adequate size, yet is not too big and allows for interesting manoeuvrers.

In order to reduce the required number of tests, only one starting scenario was used for all of the tuning of the control parameters. Start scenario 1 can be seen in Appendix \ref{fig:appendix:start_scenarios_1_2}. In Chapter \ref{chap:evaluation}, the performance of the tuned genetic algorithm on different start scenarios will be investigated.

\section{Population}
\label{sect:hyperparameter_tuning:population}
Finding a suitable population size is of high importance to a genetic algorithm, especially considering the limed processing resources available. On one hand, a population that is too small might result in less diverse runs of the genetic algorithm, on the other hand, if the population size is too high, the simulations will become too costly (see Section \ref{sect:foundations:genetic_algorithm}).

In order to evaluate the best population size, other hyperparameters first have to be fixated.
\cite{grefenstette_optimization_1986} suggests that a range of control parameter will already lead to acceptable performance, yet optimal performance needs tuning. \cite{kacprzyk_parameter_2007} complements these findings, adding that the "sweat spot" for control parameters of genetic algorithms is reasonably large and easy to find. A default set of static parameter values is generally speaking sufficient. Following this advice, the most suitable population parameters will now be evaluated by fixating the remaining hyperparameters to a small range of suggested values from the literature.

\subsection{Suggested Hyperparameter from the Literature}
After reviewing various literature regarding control parameter of genetic algorithms, no clear consensus emerged. \cite{mills_determining_2015} come to a similar conclusion, mentioning the inconsistencies between findings during their literature review and highlighting the conflicting evidence regarding "key GA control parameter".

Table \ref{tab:hyperparameter_tuning:ga_hyperparameters} aims to provide a short, tough not exhaustive, overview on different control parameter settings used in the literature. This compilation does not claim to cover the entire scope of available research in this domain, rather it served as a focused effort to identify usable hyperparameters.

\begin{table}[ht]
	\centering
	\caption{Summary of Genetic Algorithm Hyperparameters}
	\label{tab:hyperparameter_tuning:ga_hyperparameters}
	\begin{tabular}{lcccc}
		\hline
		\textbf{Parameter Set} & \textbf{Pop} & \textbf{Cross} & \textbf{Mut} & \textbf{Sel} \\
		\hline
		\cite{de_jong_analysis_1975} & 50 & 0.6 & 0.001 & ? \\
		\cite{mills_determining_2015} & 200 & ? & Adaptive & SUS\\
		\cite{grefenstette_optimization_1986} & 30 & 0.95 & 0.01 & ?\\
		\cite{grefenstette_optimization_1986} & 80 & 0.45 & 0.01 & ?\\
		\cite{almanee_scenorita_2021} & 50 & 0.8 & 0.2 & ?\\
		\cite{srinivas_genetic_1994}  & 30-100 & 0.9 & 0.01 & ?\\
		\cite{fazal_estimating_2005} & 50 & 0.5 & ? & Tourn\\
		\cite{dao_maximising_2016} & 200 & 0.7 & ? & Roul\\
		\cite{naruka_parameter_2019} & 200 & 0.4 & ? & Roul \\
		\cite{jinghui_zhong_comparison_2005} & 50-250 & 0.1-0.9 & 0.05-0.25 & ?\\
		\hline
	\end{tabular}
\end{table}

As recommended population size, a value between 30-200 is commonly proposed. In order to reduce the needed compution time, a highest possible population size of 96 is defined for the future evaluation. Further, Crossover rates are mostly be in a range of 0.6-0.9. Generally speaking, a low mutation rate is recommended. For example \cite{grefenstette_optimization_1986} suggest poor performance using a rate over 0.05. Using a low mutation rate is also suggested by \cite{whitley_genetic_1994} and \cite{jinghui_zhong_comparison_2005}. On the other hand, \cite{boyabatli_parameter_2004} found higher mutation rates for their application to be more suitable. \cite{srinivas_genetic_1994} differentiates between higher and lower population numbers, claiming that a smaller population needs higher mutation rates in order to maintain a sufficient diversity.

\subsection{Comparison of Population Size}
Based on the described research, population sizes of 32, 48, 64 and 96 will be compared. Crossover rates are set to 0.8 and 0.6. For mutation, 0.01 and 0.2 will be discussed. Further, tournament selection of 2 and 4 is used.
Individual mutation probability will stay at 0.1. Chromosome encoding is set to Time and gene encoding is set to Integer. 
Each run will be executed 5 times to reduce randomness and to make the results more robust. Each simulation will last for 30 generations. A list of all settings with the mean over 5 repetitions per population size can be seen in table \ref{tab:hyperparameter_tuning:pop_settings_results}.

\begin{table}[ht]
	\centering
	\begin{tabular}{ c|c|cccc  }
		\hline
		Settings & Code & 32 & 48 & 64 & 96\\
		\hline
		C: 0.6, M: 0.01, TS: 2   	& A & 4.49 & 4.84 & 6.49 & 6.29 \\
		C: 0.6, M: 0.01, TS: 4		& B & 3.89 & 4.79 & 4.21 & 5.63 \\ 
		C: 0.6, M: 0.20, TS: 2 		& C & 4.38 & 4.90 & 4.98 & 6.69 \\
		C: 0.6, M: 0.20, TS: 4    	& D & 4.80 & 5.33 & 6.09 & 6.50 \\
		C: 0.8, M: 0.01, TS: 2   	& E & 4.37 & 6.08 & 5.29 & 5.84 \\
		C: 0.8, M: 0.01, TS: 4		& F & 4.48 & 4.51 & 4.46 & 6.03 \\
		C: 0.8, M: 0.20, TS: 2 		& G & 4.01 & 5.60 & 5.41 & 6.31 \\
		C: 0.8, M: 0.20, TS: 4    	& H & 4.42 & 4.95 & 7.06 & 6.91 \\
		\hline
	\end{tabular}
	\caption{results from testing population size - mean of 5 repetitions}
	\label{tab:hyperparameter_tuning:pop_settings_results}
\end{table}

In Figure \ref{fig:hyperparameter_tuning:population_results}, the results per population are plotted. The line is corresponds to the mean, while the bars show the spread (min to max) of all 5 repetitions.

\begin{figure}[ht] 
	\includegraphics[width=1\linewidth]{simulations/population/plots/comparison}
	\caption{mean and error bars per population size}
	\label{fig:hyperparameter_tuning:population_results}
\end{figure}

A higher spread in the results can be seen when looking at small population sizes. Considering these findings, a population size of 96 was chosen. While such a high value will result in a performance impact, it was deemed to be more important to keep the variation low.

\section{Design of Experiment}
\label{sect:hyperparameter_tuning:design_of_experiment}
This Section aims to find optimal settings for the remaining control parameters of the given problem.
Following the conclusion from the previous Section \ref{sect:hyperparameter_tuning:population}, a population size of 96 will be fixated. 

In order to tune the control parameter of the genetic algorithm, various different strategies can be used. Using automated approaches like "grid search", "bayesian optimization, "simmulated annealing or "hyperband" might lead to good results with minimal effort (tuning of hyperparameter for these search algorithms is still needed), however they each require a high number of runs (\cite{kacprzyk_parameter_2007}).\todo{find more references} \cite{kacprzyk_parameter_2007} even suggest using a second, higher level genetic algorithm for the optimization process. Due to performance considerations, many optimization methods did not fit the requirements.
Executing one run for 30 generations takes around 3:50 hours. The high variance, between runs requires a certain number of repetitions for each setting. Although two different workstations were available, the time required to execute the needed number of runs for these automated tests would exceed the available time budged. For this Section, 8 repetitions were used per setting, which makes one evaluation last 30 hours.

A different approach is called design of experiment (DOE), also known as statistically designed experiments. DOE tries to find the cause and-effect relationship between the factors and the output of experiments.
It uses factorial design where the variables in an experiment are named 'factors'. Each factor consists of at least two settings, with the actual number of settings being called 'levels' (\cite{yang_design_2009}). Design of experiment needs manual expertise to define which factors are possibly of importance and which settings each factor should have.

\begin{quote}
	\begin{em}
		\enquote{If the range of variable is too small, then we may miss lots of useful information. If the range is too large, then the extreme values might give infeasible experimental runs.} (\cite{yang_design_2009})
	\end{em}
\end{quote}

Afterwards, main effects and interactions can be calculated to find the best settings per factor. Using ANOVA (Analysis of Variance) it is possible to identify the significance of each factor and interaction, which enables their ranking. More details on these analysis tools will be provided in Section \ref{sect:hyperparameter_tuning:analysis_of_results}.

A full factorial design will test over all possible combinations of the manually selected factor levels. Looking at the proposed factors in table \ref{tab:hyperparameter_tuning:settings_to_level}, 1024 runs\footnote{number of runs calculated using: \url{https://datatab.net/statistics-calculator/design-of-experiments}} are required, which not feasible performance wise. A full factorial design has the drawback, that as the number of factors k gets increased, the number of needed experimental runs increases exponentially, thus resulting in lengthy experiments. \cite{yang_design_2009} state, that most of the results obtained by testing over all combinations are only used for estimating higher-order interactions, which are in most cases insignificant.

\subsection{Taguchi Method}
Various improvements to design of experiment have been but forward by Dr. Genichi Taguchi, such as reducing the influence of uncontrollable (noise) factors on processes and products and reducing variability (\cite{roy_primer_1990}). This master's thesis will not discuss all of Taguchi's proposed considerations, for more detail \cite{roy_primer_1990} as well as \cite{yang_design_2009} are recommended. Taguchi's proposed design of experiment is a fractional factorial design, which requires significantly less runs. While different fractional factorial designs are available, Taguchi was chosen, because he provides a simple and easy to follow procedure which requires only a minimal number of runs. In fractional factorial designs, only a fraction of all possible combinations is investigated (\cite{roy_primer_1990}).

\begin{quote}
	\begin{em}
		\enquote{There are many similarities between “regular” experimental design and Taguchi's experimental design. However, in a Taguchi experiment, only the main effects and two-factor interactions are considered. Higher-order interactions are assumed to be non-existent. In addition, experimenters are asked to identify which interactions might be significant before conducting the experiment, through their knowledge of the subject matter.} (\cite{yang_design_2009})
	\end{em}
\end{quote}

Taguchi predefined a number of different orthogonal arrays where each row contains the specific levels (i.e the settings) of one experiment, while the columns correspond the factors (\cite{li_taguchi_2021}). Taguchi's orthogonal arrays \enquote{represent the smallest fractional factorials} (\cite{roy_primer_1990}). Only a fraction of combinations needs to be tested, drastically reducing computational needs. The researcher has the responsibility to select an array based on the individual needs (\cite{li_taguchi_2021}).
Using these orthogonal arrays instead of full factorial experiments will lead to a much smaller amount of simulation runs, while the full factorial experiments \enquote{might not provide appreciably more useful information} (\cite{roy_primer_1990}).

A big drawback of using Taguchi orthogonal arrays is the inability of evaluating higher order interaction effects. It is only possible to measure the interaction between 2-level factors. Not only are higher order interaction effects not possible to evaluate, they also have an influence on the performance. Orthogonal array experiments perform best in cases of minimal interaction between factors. While there is still a good chance of identifying the optimum condition, especially the performance estimate can be significantly off (\cite{roy_primer_1990}). While \cite{yang_design_2009} state that in many cases higher-order interaction effects in factorial designs are seldom significant, this might not be the case for genetic algorithms. For example \cite{kacprzyk_parameter_2007} claimed, that control parameters of a genetic algorithm \enquote{interact in highly non-linear ways.} If the proposed method is able to provide a suitable set of hyperparameter settings will be evaluated Chapter \ref{chap:evaluation}.

\paragraph{Selection of an Orthogonal Array}
When choosing a suitable Taguchi orthogonal array, various factors have to be taken into account. According to \cite{yang_design_2009}, a three step procedure needs to be followed:

\begin{enumerate}
	\item Calculate the total degree of freedom (DOF). 
	\item Base on the following two rules a standard orthogonal array should be selected:
	\begin{enumerate}
		\item Total DOF need to be smaller than the number of runs provided by the orthogonal array.
		\item All required factor level combinations need to be accommodated by the orthogonal array.
	\end{enumerate}
	
	\item Factors have to be assigned using these rules: 
	\begin{enumerate}
		\item In case the factor level does not fit into the orthogonal array, methods such as column merging and dummy level can be used to modify the original array.
		\item Using the linear graph and interaction table, interactions can be defined. 
		\item In case some columns are not assigned, its possible to keep these columns empty.
	\end{enumerate}
\end{enumerate}

For this design of experiment, 7 factors (3 factors of level 4 and 4 factors of level 2) have been selected. Which factors and levels to choose was done based on experience gained on Section \ref{sect:hyperparameter_tuning:population}. In table \ref{tab:hyperparameter_tuning:settings_to_level}, every factor with the corresponding levels has been listed.

\begin{table}[ht]
	\label{tab:hyperparameter_tuning:settings_to_level}
	\centering
	\small
\begin{tabular}{ l|c|cccc }
	\hline
	Factors & Code & Level 1 & Level 2 & Level 3 & Level 4\\
	\hline
	CrossoverType 		& A & one point & two point & uni$^*$ 0.1 & uni$^*$ 0.5\\
	CrossoverRate    	& B & 0.2 & 0.5 & 0.8 & 0.9\\
	MutationRate   		& C & 0.01 & 0.1 & 0.3 & 0.5\\
	ChromosomeType   	& D & Time & Time+NPC & - & -\\
	GeneType			& E & Int & Dict & - & -\\
	TournamentSize 		& F & 2 & 4 & - & -\\
	IndMutationRate		& G & 0.1 & 0.5 & - & -\\
	\hline
\end{tabular}
\caption{Control Parameters (Factors) with corresponding Settings (Levels) - ($^*$uniform)}
\end{table}

It is important to state, that Taguchi allows to only test for possible (pre determined) two-factor interactions, evaluating higher factor interactions is not possible (\cite{yang_design_2009}). Analysing interactions comes at the cost of degrees of freedom. An interaction between ChromosomeType and GeneType might be of interest and will thus be chosen. In order to minimized the required degrees of freedom (and correspondingly the required number of experiment runs), no additional interactions will be analysed.

\subsection{Selection of a Suitable Standard Orthogonal Array}
\label{sect:hyperparameter_tuning:selection_orthogonal_array}
The total degree of freedom can be calculated using the rules provided by \cite{yang_design_2009}:

\begin{enumerate}
	\item 1 DOF is always used for the overall mean. 
	\item Each factor has a DOF of NumberOfLevels - 1.
	\item Two-factor interactions use this equation to calculate DOF: $(n_{factor1} - 1)(n_{factor2} - 1)$ where $n$ = number of levels.
\end{enumerate}

This leads to the following calculation for the needed 3 factors of level 4 and 4 factors of level 2 as well as the interaction ChromosomeType-GeneType:

\begin{equation} \label{equ:hyperparam_tuning:DOF}
	\begin{split}
		DOF & = 1 + 3 * (4 - 1) + 4 * (2 - 1) + 1 * (2 - 1) * (2 - 1) \\
		& = 15
	\end{split}
\end{equation}

A $L_{16}$ array seems suitable to accommodate the required 15 DOF, which can be seen in table \ref{tab:hyperparameter_tuning:L16_orhtogonal_array}.

\begin{table}[ht]
	\label{tab:hyperparameter_tuning:L16_orhtogonal_array}
	\centering
\begin{tabular}{ |c||c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|  }
	\hline
	   & \multicolumn{15}{c|}{ $L_{16}(2^{15})$ } \\
	NO.& 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10& 11& 12& 13& 14&15\\
	\hline
	1  & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
	2  & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2\\
	3  & 1 & 1 & 1 & 2 & 2 & 2 & 2 & 1 & 1 & 1 & 1 & 2 & 2 & 2 & 2\\
	4  & 1 & 1 & 1 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 1 & 1 & 1 & 1\\
	5  & 1 & 2 & 1 & 1 & 1 & 2 & 2 & 1 & 1 & 2 & 2 & 1 & 1 & 2 & 2\\
	6  & 1 & 2 & 2 & 1 & 1 & 2 & 2 & 2 & 2 & 1 & 1 & 2 & 2 & 1 & 1\\
	7  & 1 & 2 & 2 & 2 & 2 & 1 & 1 & 1 & 1 & 2 & 2 & 2 & 2 & 1 & 1\\
	8  & 1 & 2 & 2 & 2 & 2 & 1 & 1 & 2 & 2 & 1 & 1 & 1 & 1 & 2 & 2\\
	9  & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 1 & 2\\
	10 & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 1\\
	11 & 2 & 1 & 2 & 2 & 1 & 2 & 1 & 1 & 2 & 1 & 2 & 2 & 1 & 2 & 1\\
	12 & 2 & 1 & 2 & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 1 & 1 & 2 & 1 & 2\\
	13 & 2 & 2 & 1 & 1 & 2 & 2 & 1 & 1 & 2 & 2 & 1 & 1 & 2 & 2 & 1\\
	14 & 2 & 2 & 1 & 1 & 2 & 2 & 1 & 2 & 1 & 1 & 2 & 2 & 1 & 1 & 2\\
	15 & 2 & 2 & 1 & 2 & 1 & 1 & 2 & 1 & 2 & 2 & 1 & 2 & 1 & 1 & 2\\
	16 & 2 & 2 & 1 & 2 & 1 & 1 & 2 & 2 & 1 & 1 & 2 & 1 & 2 & 2 & 1\\
	\hline
\end{tabular}
\caption{ $L_{16}(2^{15})$ Taguchi orthogonal array taken from \cite{roy_primer_1990}}
\end{table}

4 level factors need additional space which will be generated using column merging, while the interaction will need to be assigned as well.
Either an interaction table or linear graphs of the $L_{16}$ array can be used for both column merging and interaction assignment (\cite{nazandanacioglu_taguchi_2005}). Both illustrate the interaction relationships in the orthogonal array (\cite{yang_design_2009}).
The linear graph is more straight forward and will be the chosen approach. While there are multiple linear graphs for the $L_{16}$ array, \ref{fig:hyperparameter_tuning:linear_graph} describes the graph which best fits the requirements from table \ref{tab:hyperparameter_tuning:settings_to_level}. If no suitable graph is found, they can be modified using rules described by \cite{nazandanacioglu_taguchi_2005}.

\begin{figure}[H]
	\label{fig:hyperparameter_tuning:linear_graph}
	\centering
\begin{tikzpicture}
	% Define 1 2 3
	\node (Node2) at (0,0) {2};
	\node (Middle12) at (0,1) {};
	\node (Eclipse12) at (-0.8,0) {};
	\node (Node1) at (0,2) {1};
	
	\draw (Node2) -- node[midway, right] {3} (Node1);
	
	
	% Define 4 8 12
	\node (Node8) at (2,0) {8};
	\node (Middle84) at (2,1) {};
	\node (Eclipse84) at (1.2,0) {};
	\node (Node4) at (2,2) {4};
	
	\draw (Node8) -- node[midway, right] {12} (Node4);
	
	% Define 5 15 10
	\node (Node10) at (4,0) {10};
	\node (Middle105) at (4,1) {};
	\node (Eclipse105) at (3.2,0) {};
	\node (Node5) at (4,2) {5};
	
	\draw (Node10) -- node[midway, right] {15} (Node5);
	
	% Define 7 9 14
	\node (Node9) at (6,0) {9};
	\node (Node7) at (6,2) {7};
	
	\draw (Node9) -- node[midway, right] {14} (Node7);
	
	% Define 6 11 13
	\node (Node11) at (8,0) {11};
	\node (Node6) at (8,2) {6};
	
	\draw (Node11) -- node[midway, right] {13} (Node6);
\end{tikzpicture}
\caption{Linear Graph of $L_{16}(2^{15})$ taken from \cite{yang_design_2009}}
\end{figure}

In a Taguchi linear graph, the nodes as well as the connections both represent columns in the orthogonal array. The interaction between two nodes is described by the connecting line (\cite{taguchi_taguchis_2005}). This is useful for both analysing interactions between columns as well as combining (merging) interacting columns in case a higher factor is needed.

\paragraph{Column Merging}
A, B and C are both 4 level factors. The currently selected orthogonal array only fits 2 level factors. Column merging, it is possible to extend columns to accommodate higher order levels. 

As calculated in \ref{equ:hyperparam_tuning:DOF}, a four-level column requires three degrees of freedom, thus three two-level columns need to be merged. Column merging needs the to be merged columns to be part of an interaction group (\cite{yang_design_2009}). The available interaction groups are visualized by the linear graph in Figure \ref{fig:hyperparameter_tuning:linear_graph}.

3 2-level interaction columns need to be selected first. One column is discarded, the remain two columns are merged using the rules in tabular \ref{tab:hyperparameter_tuning:merging_rules}.

\begin{table}[ht]
	\centering
	\begin{tabular}{ |ccccccc|  }
		\hline
		\multicolumn{3}{|c}{ OLD COLUMN } & & & & NEW COLUMN \\
		\hline
		& 1 & 1 & & -> & & 1\\
		& 1 & 2 & & -> & & 2\\
		& 2 & 1 & & -> & & 3\\
		& 2 & 2 & & -> & & 4\\
		\hline
	\end{tabular}
	\caption{Rules taken from \cite{roy_primer_1990}}
	\label{tab:hyperparameter_tuning:merging_rules}
\end{table}

The four-level factor can then be assigned to this newly generated column. Because three four-level factors are needed for the current experiment, nine two-level columns have to be merged in total.

\paragraph{Assigning Interactions}
The interaction between both two-level factors can be assigned using the linear graph as well. An interaction between ChromosomeType and GeneType seems possible, thus D and E will be assigned to connected nodes in the linear graph. The resulting graph can be seen in \ref{fig:hyperparameter_tuning:linear_graph_assigned}. An interaction between F and G can not be investigated, as the chosen orthogonal array is not able to fit the additional 1 degree of freedom (see equation \ref{equ:hyperparam_tuning:DOF}).

\begin{figure}[H]
	\centering
	\label{fig:hyperparameter_tuning:linear_graph_assigned}
\begin{tikzpicture}
	% Define 1 2 3
	\node (Node2) at (0,0) {2};
	\node (Middle12) at (0,1) {};
	\node (Eclipse12) at (-0.8,0) {};
	\node (Node1) at (0,2) {1};
	\node[red] (A) at (-1.5, -1) {A};

	\draw (Node2) -- node[midway, right] {3} (Node1);
	\draw (Middle12) ellipse (0.8cm and 1.5cm);
	\draw[->, thick] (Eclipse12) to[bend right=20] (A);
	
	
	% Define 4 8 12
	\node (Node8) at (2,0) {8};
	\node (Middle84) at (2,1) {};
	\node (Eclipse84) at (1.2,0) {};
	\node (Node4) at (2,2) {4};
	\node[red] (B) at (0.5, -1) {B};
	
	\draw (Node8) -- node[midway, right] {12} (Node4);
	\draw (Middle84) ellipse (0.8cm and 1.5cm);
	\draw[->, thick] (Eclipse84) to[bend right=20] (B);
	
	% Define 5 15 10
	\node (Node10) at (4,0) {10};
	\node (Middle105) at (4,1) {};
	\node (Eclipse105) at (3.2,0) {};
	\node (Node5) at (4,2) {5};
	\node[red] (C) at (2.5, -1) {C};
	
	\draw (Node10) -- node[midway, right] {15} (Node5);
	\draw (Middle105) ellipse (0.8cm and 1.5cm);
	\draw[->, thick] (Eclipse105) to[bend right=20] (C);
	
	% Define 7 9 14
	\node (Node9) at (6,0) {9};
	\node (Node7) at (6,2) {7};
	\node[red] (E) at (6.5,0) {E};
	\node[red] (D) at (6.5,2) {D};
	\node[red] (DE) at (7,1) {DE};
	
	\draw (Node9) -- node[midway, right] {14} (Node7);
	
	
	% Define 6 11 13
	\node (Node11) at (8,0) {11};
	\node (Node6) at (8,2) {6};
	\node[red] (G) at (8.5,0) {G};
	\node[red] (F) at (8.5,2) {F};
	\node (FG) at (9,1) {};
	
	\draw (Node11) -- node[midway, right] {13} (Node6);
\end{tikzpicture}
\caption{Modified Linear Graph to fit our needs}
\end{figure}


Combining columns 1 2 3 to A, 4 8 12 to B and 5 10 15 to C using rules defined by table \ref{tab:hyperparameter_tuning:merging_rules} is done in \ref{tab:hyperparameter_tuning:merging_columns}.

\begin{table}[ht]
	\centering
	\begin{tabular}{ |c||cccc|cccc|cccc|  }
		\hline
		NO.& 1 & 2 & & \sout{3} & 4 & 8 & &  \sout{12} & 5 & 10 & &  \sout{15}\\
		\hline
		1  & \multicolumn{4}{c}{\sout{1 1} > 1 } & \multicolumn{4}{|c|}{\sout{1 1} > 1 } & \multicolumn{4}{c|}{\sout{1 1} > 1 }\\
		2  & \multicolumn{4}{c}{\sout{1 1} > 1 } & \multicolumn{4}{|c|}{\sout{1 2} > 2 } & \multicolumn{4}{c|}{\sout{1 2} > 2 }\\
		3  & \multicolumn{4}{c}{\sout{1 1} > 1 } & \multicolumn{4}{|c|}{\sout{2 1} > 3 } & \multicolumn{4}{c|}{\sout{2 1} > 3 }\\
		4  & \multicolumn{4}{c}{\sout{1 1} > 1 } & \multicolumn{4}{|c|}{\sout{2 2} > 4 } & \multicolumn{4}{c|}{\sout{2 2} > 4 }\\
		5  & \multicolumn{4}{c}{\sout{1 2} > 2 } & \multicolumn{4}{|c|}{\sout{1 1} > 1 } & \multicolumn{4}{c|}{\sout{1 2} > 2 }\\
		6  & \multicolumn{4}{c}{\sout{1 2} > 2 } & \multicolumn{4}{|c|}{\sout{1 2} > 2 } & \multicolumn{4}{c|}{\sout{1 1} > 1 }\\
		7  & \multicolumn{4}{c}{\sout{1 2} > 2 } & \multicolumn{4}{|c|}{\sout{2 1} > 3 } & \multicolumn{4}{c|}{\sout{2 2} > 4 }\\
		8  & \multicolumn{4}{c}{\sout{1 2} > 2 } & \multicolumn{4}{|c|}{\sout{2 2} > 4 } & \multicolumn{4}{c|}{\sout{2 1} > 3 }\\
		9  & \multicolumn{4}{c}{\sout{2 1} > 3 } & \multicolumn{4}{|c|}{\sout{1 1} > 1 } & \multicolumn{4}{c|}{\sout{2 1} > 3 }\\
		10 & \multicolumn{4}{c}{\sout{2 1} > 3 } & \multicolumn{4}{|c|}{\sout{1 2} > 2 } & \multicolumn{4}{c|}{\sout{2 2} > 4 }\\
		11 & \multicolumn{4}{c}{\sout{2 1} > 3 } & \multicolumn{4}{|c|}{\sout{2 1} > 3 } & \multicolumn{4}{c|}{\sout{1 1} > 1 }\\
		12 & \multicolumn{4}{c}{\sout{2 2} > 3 } & \multicolumn{4}{|c|}{\sout{2 2} > 4 } & \multicolumn{4}{c|}{\sout{1 2} > 2 }\\
		13 & \multicolumn{4}{c}{\sout{2 2} > 4 } & \multicolumn{4}{|c|}{\sout{1 1} > 1 } & \multicolumn{4}{c|}{\sout{2 2} > 4 }\\
		14 & \multicolumn{4}{c}{\sout{2 2} > 4 } & \multicolumn{4}{|c|}{\sout{1 2} > 2 } & \multicolumn{4}{c|}{\sout{2 1} > 3 }\\
		15 & \multicolumn{4}{c}{\sout{2 2} > 4 } & \multicolumn{4}{|c|}{\sout{2 1} > 3 } & \multicolumn{4}{c|}{\sout{1 2} > 2 }\\
		16 & \multicolumn{4}{c}{\sout{2 2} > 4 } & \multicolumn{4}{|c|}{\sout{2 2} > 4 } & \multicolumn{4}{c|}{\sout{1 1} > 1 }\\
		\hline
	\end{tabular}
	\caption{Building 4 Level columns from 2 Level columns}
	\label{tab:hyperparameter_tuning:merging_columns}
\end{table}

Removing the old and inserting the new columns in the table and transcoding 7 to D, 9 to E, 14 to DE, 6 to F, 11 to G and 13 to FG results in the final table \ref{tab:hyperparameter_tuning:final_taguchi}.
This combination table will subsequently be used as settings for the simulation runs.

\begin{table}[ht]
	\centering
	\begin{tabular}{ |c||c|c|c|c|c|c|c|c|  }
		\hline
		NO.& A & B & C & D & E & F & G & DE\\
		\hline
		1  & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
		2  & 1 & 2 & 2 & 1 & 2 & 1 & 2 & 2\\
		3  & 1 & 3 & 3 & 2 & 1 & 2 & 1 & 2\\
		4  & 1 & 4 & 4 & 2 & 2 & 2 & 2 & 1\\
		5  & 2 & 1 & 2 & 2 & 1 & 2 & 2 & 2\\
		6  & 2 & 2 & 1 & 2 & 2 & 2 & 1 & 1\\
		7  & 2 & 3 & 4 & 1 & 1 & 1 & 2 & 1\\
		8  & 2 & 4 & 3 & 1 & 2 & 1 & 1 & 2\\
		9  & 3 & 1 & 3 & 2 & 2 & 1 & 2 & 1\\
		10 & 3 & 2 & 4 & 2 & 1 & 1 & 1 & 2\\
		11 & 3 & 3 & 1 & 1 & 2 & 2 & 2 & 2\\
		12 & 3 & 4 & 2 & 1 & 1 & 2 & 1 & 1\\
		13 & 4 & 1 & 4 & 1 & 2 & 2 & 1 & 2\\
		14 & 4 & 2 & 3 & 1 & 1 & 2 & 2 & 1\\
		15 & 4 & 3 & 2 & 2 & 2 & 1 & 1 & 1\\
		16 & 4 & 4 & 1 & 2 & 1 & 1 & 2 & 2\\
		\hline
	\end{tabular}
	\caption{Final version of used Taguchi orthogonal array}
	\label{tab:hyperparameter_tuning:final_taguchi}
\end{table}


\subsection{Result Analysis}
\label{sect:hyperparameter_tuning:analysis_of_results}
The final table \ref{tab:hyperparameter_tuning:final_taguchi} will be used for running all the needed testcases (the interaction columns can be ignored until the evaluation). Transcoding all factors and levels to get the corresponding setting can be done using the table from \ref{tab:hyperparameter_tuning:settings_to_level}. Every setting will be repeated 8 times to reduce randomness and gain information about variance. 
Running the genetic algorithm with these 16 different settings each repeated 8 times took 10 days on the two in Section \ref{sect:hyperparameter_tuning:simulation_setup} described workstations. The results are found in the Appendix at \ref{tab:appendix:hyperparameter_tuning_final_taguchi}.

\subsubsection{ANOVA}
ANOVA analysis (analysis of variance) will provide information on the magnitude of contribution of the main effects and interactions. The calculation of ANOVA on a Taguchi experiment is the same as for a classical design of experiment (\cite{yang_design_2009}). Calculating ANOVA is done using the programming language R\footnote{\href{https://www.r-project.org/}{https://www.r-project.org/}} and the result can be seen in Table \ref{tab:taguchi:anova_results}.

\begin{table}[ht]
	\centering
	\begin{tabular}{lrrrrr}
		\hline
		& Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\ 
		\hline
		A & 3 & 23.89 & 7.96 & 6.59 & 0.0004 \\ 
		B & 3 & 5.00 & 1.67 & 1.38 & 0.2532 \\ 
		C & 3 & 34.32 & 11.44 & 9.46 & 0.0000 \\ 
		D & 1 & 3.88 & 3.88 & 3.21 & 0.0759 \\ 
		E & 1 & 0.35 & 0.35 & 0.29 & 0.5912 \\ 
		F & 1 & 18.91 & 18.91 & 15.64 & 0.0001 \\ 
		G & 1 & 6.98 & 6.98 & 5.77 & 0.0179 \\ 
		D:E & 1 & 4.10 & 4.10 & 3.40 & 0.0680 \\ 
		Residuals & 113 & 136.60 & 1.21 &  &  \\ 
		\hline
	\end{tabular}
	\caption{ANOVA results}
	\label{tab:taguchi:anova_results}
\end{table}

The sum of squares of a model tell how much of the total variation is explained by the model. The variance is broken down into the factors A-G along with the interaction D:E. The residual sum of squares shows the difference between the models prediction versus what was actually observed (i.e the variance that can not be explained by the model) (\cite{field_discovering_2012}). The F ratio (or value) measures the ratio of variance explained by the factor and the variation explained by the error term (\cite{field_discovering_2012}). Simply speaking, how good is the model versus how bad is the model. Finally, the p value (in column labelled Pr(>F)) shows how likely the size of the given F ratio is obtained in case there is no effect on the results. Commonly, if p is smaller than 0.05, the effect can be viewed as statistically significant (\cite{field_discovering_2012}).

The higher number of DOF can be explained with the number of repetitions and can be calculated with the equation \ref{equ:hyperparam_tuning:full_DOF} (taken from \cite{roy_primer_1990}).

\begin{equation} \label{equ:hyperparam_tuning:full_DOF}
	\begin{split}
		DOF & = totalNumberOfResults - 1 \\
		& = numberOfTrials * numberOfRepetitions - 1 \\
		& = 16 * 8 - 1 = 127
	\end{split}
\end{equation}

The multiple R-squared value of the model is 0.416 while the adjusted R-squared value is 0.344. Multiple R-squared gives a measure on how much variability in the outcome is explained by the predictors (\cite{field_discovering_2012}). Having only 41.6\% does not seem optimal. \cite{field_discovering_2012} state further that a model which generalizes well has an adjusted R-squared value that is similar to multiple R-squared, which is also not the case in this scenario.
The high error might possibly be explained by the huge search space in the scenario. Increasing the population and number of generations might lead to improvements, however at the cost of computational time. If the model, having this much of an error, will perform well compared to either a genetic algorithm build from values from the literature or compared to random search will be evaluated in Section \ref{chap:evaluation}.

Looking at the factors as well as the interaction, significant main effects can be seen. The highest F value has the main effect F (TournamentSize). The effect is significant with F(1, 112) = 15.64, p < 0.001. Next, the effect C (MutationRate) is significant with F(3, 112) = 9.46, p < 0.001. A (CrossoverType) is also significant F(3, 112) = 6.59, p < 0.001. Finally G (IndependendMutationRate) is significant with F(1, 112) = 5.77, p < 0.05.
D (ChromosomeType) and the interaction D:E will be mentioned as well with F(1, 112) = 3.21, p < 0.1 and F(1, 112) = 3.4, p < 0.1 respectively.
There is not enough evidence that suggests significant main effects for the factors B (CrossoverRate) and E (GeneType).

Especially the fact, that the CrossoverRate does not show significant effects is surprising, which is not supported by the literature (todo: find references). The low influence of GeneType however might be explained by the fact, that it does not have a huge impact on the action selected apart from more granularity of the parameters when Dictionary encoding is used.

To look at the percentage contribution of each factor the formulas \ref{equ:hyperparam_tuning:ss_t} and \ref{equ:hyperparam_tuning:contribution} (gathered by \cite{yang_design_2009}) are used.

\begin{equation} \label{equ:hyperparam_tuning:ss_t}
	\begin{split}
		SS_T & = SS_A + SS_B + SS_C + ... + SS_{error}
	\end{split}
\end{equation}

Example calculation for factor A.
\begin{equation} \label{equ:hyperparam_tuning:contribution}
	\begin{split}
		contribution_A = SS_A / SS_T * 100
	\end{split}
\end{equation}

The percentage contribution of all factors is plotted in \ref{fig:hyperparam_tuning:percentage_contribution} and shows the high error of the model. 
\begin{figure}[ht] 
	\label{fig:hyperparam_tuning:percentage_contribution}
	\includegraphics[width=1\linewidth]{simulations/taguchi/plots/percentage_contribution}
	\caption{Percentage Contribution}
\end{figure}

\subsubsection{Main-effects and interaction chart}
Identifying the optimal conditions needs analysis of the main effects per factor. They allow to predict the levels, that lead to the best result (\cite{roy_primer_1990}).

\begin{quote}
	\begin{em}
		\enquote{The main-effects chart is a plot of average responses at different levels of a factor versus the factor levels.} (\cite{yang_design_2009})
	\end{em}
\end{quote}

For every factor, sum up the mean of all results per level, then divide by the number of runs per level.

\todo{Show calculation example for D}

The resulting main-effect charts can be seen in Figure \ref{fig:hyperparam_tuning:main_effects}.
\begin{figure}[ht] 
	\label{fig:hyperparam_tuning:main_effects}
	\includegraphics[width=1\linewidth]{simulations/taguchi/plots/main_effects}
	\caption{Main Effects}
\end{figure}


In case there is no interaction, the optimal setting is easily determined by using the main effects chart. Go over every factor in the chart and use the best level (in case of this experiment, the level with the highest value). 

If interactions exist, they might have an influence on the best settings and need further investigation (\cite{yang_design_2009}). To investigate the previously defined interaction an interaction graph can be used. The calculation is similar to calculating main effects and shown in Figure \ref{fig:hyperparam_tuning:test_of_interaction}.

\todo{Show calculation example for DE}

\begin{figure}[ht] 
	\label{fig:hyperparam_tuning:test_of_interaction}
	\centering
	\includegraphics[width=0.4\linewidth]{simulations/taguchi/plots/test_of_interaction}
	\caption{Test of interactions}
\end{figure}

The crossing of lines indicates, that an interaction between the two factors might exist (\cite{field_discovering_2012}). The more parallel the lines are, the less likely an interaction. Magnitude of the angle between the lines corresponds to the degree of interaction presence, according to (\cite{roy_primer_1990}).

\subsubsection{Selection of optimal setting}
When choosing the optimal setting, the first step is to look at the best main effects combination. For this experiment, the best combination according the main effects is the following: A4, B4, C3, D2, E2, F2, G1.

Analysing the ANOVA table, the interaction D:E however seams to have significance, especially compared to E. According to (\cite{field_discovering_2012}), it makes little sense to further interpret main effects if the interaction effect is significant (which it almost is with p < 0.1), thus this interaction will be integrated.

The test of interaction in Figure \ref{fig:hyperparam_tuning:test_of_interaction} suggest D2 and E1 as the best combination. This is optimal, as D2 is also recommended by the main effects. While E1 does not correspond to its main effect, the low F value suggests low significance for E anyway. Concluding this line of thought, the combination A4, B4, C3, D2, E1, F2, G1 seems to be optimal.

\paragraph{Optimum performance calculation}
\label{sect:hyperparameter_tuning:optimum_perf_caluclation}
To calculate the predicted results of an algorithm with these settings, optimal performance calculation can be used. Equation \ref{equ:hyperparameter_tuning:optimum_perf_main_effect} only uses the optimal main effects while equation \ref{equ:hyperparameter_tuning:optimum_perf_included_interaction} has the interaction D:E applied. The calculation formulas are provided by \cite{roy_primer_1990}.

\begin{equation} \label{equ:hyperparameter_tuning:optimum_perf_main_effect}
	\begin{split}
		Y_{opt} &= \overline{T} + (\overline{A_4} - \overline{T}) + (\overline{B_4} - \overline{T}) + (\overline{C_3} - \overline{T}) + (\overline{D_2} - \overline{T}) + \\& (\overline{E_2} - \overline{T}) + (\overline{F_2} - \overline{T}) + (\overline{G_1} - \overline{T}) \\
			&= 8.06
	\end{split}
\end{equation}


\begin{equation} \label{equ:hyperparameter_tuning:optimum_perf_included_interaction}
	\begin{split}
		Y_{opt} &= \overline{T} + (\overline{A_4} - \overline{T}) + (\overline{B_4} - \overline{T}) + (\overline{C_3} - \overline{T}) + (\overline{D_2} - \overline{T}) + \\& (\overline{E_1} - \overline{T})  + ([\overline{DxE}]_2 - \overline{T})  + (\overline{F_2} - \overline{T}) + (\overline{G_1} - \overline{T}) \\
		&= 8.13
	\end{split}
\end{equation}

Utilizing the interaction D:E, the performance estimation improves from 8.06 to 8.13. Finally the optimized settings are as follows:
CrossoverType: Uniform 0.5, CrossoverPropability: 0.9, MutationPropability: 0.3, ChromosomeType: Time+NPC, GeneType: Integer, TournamentSize: 4 and IndividualMutationPropability: 0.1.
\todo{Talk about high randomness in  the recommended settings}

\subsubsection{Signal-to-Noise Ratio}
As previously discussed, the ANOVA model has a high error, which suggests high randomness. Taguchi recommends using signal-to-noise (S/N) ratio to reduce the variability, as using only the mean of the results does not take the variation into account (\cite{roy_primer_1990}). The greater the signal-to-noise ratio, the smaller the variance.

\begin{quote}
	\begin{em}
		\enquote{use of the S/N ratio offers an objective way to look at the two characteristics (consistency and average value) together.} (\cite{roy_primer_1990})
	\end{em}
\end{quote}

S/N is calculated in two steps, according to \cite{roy_primer_1990}. First the mean square deviation (MSD) is needed. Depending on the quality characteristic, a different equation has to be chosen. In this case, a higher result is better, thus equation \ref{equ:hyperparam_tuning:MSD} is used for each repetition, with y being a result and n the number of repetitions.

\begin{equation} \label{equ:hyperparam_tuning:MSD}
	\begin{split}
		MSD & = (1/y^2_1 + 1/y^2_2 + 1/y^2_3 + ... ) / n
	\end{split}
\end{equation}

S/N is further calculated using equation \ref{equ:hyperparam_tuning:S_N}.

\begin{equation} \label{equ:hyperparam_tuning:S_N}
	\begin{split}
		S/N & = -10 log_{10} (MSD)
	\end{split}
\end{equation}

Generating main effects and ANOVA is now done using S/N instead. As a side note, only 15 DOF for the ANOVA analysis are available, as repetitions per run get merged into 1 result (in contrast to \ref{equ:hyperparam_tuning:DOF}), which can be seen in equation \ref{equ:hyperparam_tuning:S_N_anova_DOF}.

\begin{equation} \label{equ:hyperparam_tuning:S_N_anova_DOF}
	\begin{split}
		DOF & = totalNumberOfResults - 1 \\
		& = numberOfTrials * 1 - 1 \\
		& = 16 - 1 = 15
	\end{split}
\end{equation}

The resulting ANOVA table can be seen in \ref{tab:hyperparameter_tuning:s_n_anova_results}.

\begin{table}[ht]
	\centering
	\begin{tabular}{lrrrrr}
		\hline
		& Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\ 
		\hline
		A & 3 & 5.14 & 1.71 & 3.54 & 0.3682 \\ 
		B & 3 & 2.04 & 0.68 & 1.40 & 0.5397 \\ 
		C & 3 & 10.59 & 3.53 & 7.28 & 0.2644 \\ 
		D & 1 & 1.29 & 1.29 & 2.67 & 0.3498 \\ 
		E & 1 & 0.39 & 0.39 & 0.81 & 0.5329 \\ 
		F & 1 & 4.43 & 4.43 & 9.15 & 0.2033 \\ 
		G & 1 & 2.28 & 2.28 & 4.70 & 0.2751 \\ 
		D:E & 1 & 0.92 & 0.92 & 1.89 & 0.4005 \\ 
		Residuals & 1 & 0.48 & 0.48 &  &  \\ 
		\hline
	\end{tabular}
		\caption{S/N ANOVA results}
	\label{tab:hyperparameter_tuning:s_n_anova_results}
\end{table}

When looking at the p values of this table, it is obvious that no factor can discard the null-hypothesis, which states that a factor has no significant effect. Considering this fact, it was deemed to not be necessary to perform further investigations. The often recommend signal-to-noise ratio does not seem to suitable for this experiment, thus the previously calculated settings in paragraph \ref{sect:hyperparameter_tuning:optimum_perf_caluclation} will not be adjusted.

\subsubsection{Elite Selection}
Although the optimal hyperparameter setting are discussed in Chapter \ref{chap:evaluation}, a problem was obvious when analysing results of a GA using the settings from \ref{sect:hyperparameter_tuning:optimum_perf_caluclation}. Setbacks in the optimal cost between two generations happen frequently, likely due to the high crossover and mutation rates. In order to mitigate this problem, it was decided to implement elite selection with a size of 2. Per generation, the two best individuals are now copied into the next generation without modifications, which makes worse performance between generations not possible. It is important to note, that these two individuals can still be selected by tournament selection for modification, its just that a copy of them is automatically saved. Figure \ref{fig:hyperparameter_tuning:elite_no_elite_comp} compares both no elite selection with an elite selection of 2. For a few selected repetitions, the best individual cost per generation is plotted.

\begin{figure}[ht] 
	\label{fig:hyperparameter_tuning:elite_no_elite_comp}
	\includegraphics[width=1\linewidth]{simulations/evaluation/plots/elite_vs_no_elite_generations}
	\caption{Elite Selection Comparison}
\end{figure}

For analysing the statistical significance in the differences in mean between the a genetic algorithm using elite selection of 2 vs no elite selection, a t-test can be used. In order to ignore possible violation of the assumption of homogeneity, a robust welch t-test is applied which adjusts the DOF accordingly (\cite{field_discovering_2012}).

On average, using elite improved the performance (M = 8.52, SE = 0.31), compared to using no elite (M = 7.92, SE = 0.55). This difference was not significant \textit{t}(14.21) = 0.96, p > 0.05; however, it did represent a small-sized effect r = 0.25. A comparison of both settings each repeated 10 times can be seen in Figure \ref{fig:hyperparameter_tuning:elite_comparison}.

\begin{figure}[ht] 
	\label{fig:hyperparameter_tuning:elite_comparison}
	\includegraphics[width=1\linewidth]{simulations/evaluation/plots/elite_vs_no_elite}
	\caption{Comparison Elite Selection vs No Elite Selection}
\end{figure}

Due to the existence of the mentioned small effect, it is concluded that the slightly modified version of the settings from \ref{sect:hyperparameter_tuning:optimum_perf_caluclation} will be used in Chapter \ref{chap:evaluation}, where elite selection is set to 2.

\paragraph{Effect Size}
According to \cite{field_discovering_2012} effect sizes provide an objective measure on the importance of an effect, where 0 means no effect and 1 means a perfect effect. They allow for a standardized measure and are not affected by sample size. He further recommends to use the widely used suggestions made by Cohen (\cite{cohen_statistical_1988}, \cite{cohen_power_1992}) on defining between a large or small effect:

\begin{itemize}
	\item r = .10 (small effect): The effect explains 1\% of the variance. 
	\item r = .30 (medium effect): The effect explains 9\% of the variance. 
	\item r = .50 (large effect): The effect explains 25\% of the variance.
\end{itemize} 

Effect sizes will be further used to compare different algorithms in Chapter \ref{chap:evaluation} as well and are calculated for a t test using equation \ref{equ:hyperparameter_tuning:effect_size}.
\begin{equation} \label{equ:hyperparameter_tuning:effect_size}
	\begin{split}
		r & = \sqrt{\frac{t^2}{t^2 + DOF}}
	\end{split}
\end{equation}




